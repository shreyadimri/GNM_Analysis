[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Green Nest Material Meta-Analysis",
    "section": "",
    "text": "What is this?\nData analysis are a complex thing.. often hard to reproduce. This is a website/book (depending on how you are viewing it currently) trying to walk you through the million little things that were done to generate results for this meta-analysis. Hopefully it will help increase transparency for anyone trying to understand what was done.. and if not, well, I am doing my bit to generate more data in this massive sea of information that is drowning us. You be the judge of what is useful and what is not.\nThis meta-analysis was pre-registered on OSF and you can find more details about it here:",
    "crumbs": [
      "What is this?"
    ]
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Green Nest Material Meta-Analysis",
    "section": "Contact",
    "text": "Contact\nIf you have any questions or find any mistakes or bugs to report, please contact:\nShreya Dimri\nDepartment of Evolutionary Biology,\nUniveristy of Bielefeld, Bielefeld, Germany\nEmail: shreya.dimri@uni-bielefeld.de\nGithub: https://github.com/shreyadimri",
    "crumbs": [
      "What is this?"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  About the project",
    "section": "",
    "text": "Many birds are reported to add green nest material to their nest. These green material could be leaves, sprigs and branches of aromatic herbs and trees, showing some preferential selection of the material. Some species bring these additional material even after the completion of nest building. This has led researchers to understand the functional benefits of this behaviour through both observation and experiments. This behaviour has been reviewed in detail in Dubiec, Góźdź, and Mazgajski (2013) and Scott-Baumann and Morgan (2015). We wanted to quantitatively synthesize the experimental studies investigating the function of green nest material and to test some of the several hypothesis suggested in the field. We conducted a systematic review and meta-analysis to do so.\nOur project wanted to understand if the addition of green material to the nest have any benefits across bird species that show this behaviour?\nThere are many hypothesis suggested for how the this behaviour could be beneficial to the birds. Three common hypothesis suggested are courtship hypothesis, nest protection hypothesis and drug hypothesis. We wanted to understand what the support for any of these hypothesis. We wanted to understand if this behaviour increases their reproductive success (therefore showing support to courtship hypothesis suggested in the literature)? Does the addition of green nest material by birds lead to protective effect and/or increased health benefits for the nestling (therefore showing support to nest protection or drug hypothesis. We combine the two and call it parental care hypothesis)\n\n\n\n\nDubiec, Anna, Iga Góźdź, and Tomasz D. Mazgajski. 2013. “Green Plant Material in Avian Nests.” Avian Biology Research 6 (2): 133–46. https://doi.org/10.3184/175815513X13615363233558.\n\n\nScott-Baumann, James F., and Eric R. Morgan. 2015. “A Review of the Nest Protection Hypothesis: Does Inclusion of Fresh Green Plant Material in Birds’ Nests Reduce Parasite Infestation?” Parasitology 142 (8): 1016–23. https://doi.org/10.1017/S0031182015000189.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About the project</span>"
    ]
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "2  Data Cleaning",
    "section": "",
    "text": "2.0.0.1 Setting up the space\nCode\n# If you do not have pacman package, please install it using:\n  # install.packages(\"packman\")\npacman::p_load(here,dplyr, readxl, tidyverse, stringr, knitr)\n#Packages needed for cleaning the data..\n\nrm(list=ls()) ## clearing up any previously present variables",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "data_cleaning.html#about-the-data",
    "href": "data_cleaning.html#about-the-data",
    "title": "2  Data Cleaning",
    "section": "2.1 About the data",
    "text": "2.1 About the data\nAfter conducting the title and abstract screening, we were left with 40 articles included in our dataset. We conducted full-text screening and data extraction together. We excluded studies that did not meet our inclusion criteria and if a study was included, we proceeded with data extraction. The 40 articles were randomly divided between SD, TR and JMGS. Later, on 12th August 2024, we repeated our search and performed abstract and title screening, we found 2 additional articles.\nTo summarise..\n\nWe had 40 papers after abstract and title screening\nWe found 2 papers from from repeating the search on 12th August 2024\nWe found 1 paper from other source (from Meinolf’s poster)\nWe got access to 2 Unpublished datasets (One was provided by Meinolf on buzzards and another was a Master Thesis project from Adele Menerate’s students)\n\nImporting files after data extraction\nYou can. find all the data that is needed for this analysis.. in a folder called input. In short, we need the following files to run the data cleaning:\n\ndata_extraction_setJMGS_checkedSD.xlsx\ndata_extraction_setSD_checkedTR.xlsx\ndata_extraction_setTR_checkedJS_checkedSD.xlsx\ndata_extraction_repeat_search_JMGS.xlsx\ndata_extraction_repeat_search_SD.xlsx\ndata_extraction_repeat_search_TR.xlsx\ndata_extraction_MO_checkedSD.xlsx\ndata_extraction_UnpublishedThesis.xlsx\n\n\n\nCode\n## We use column_types to make the loading variable datatype of all the datafiles same.\n\ncolumn_types= c(\"text\", \"text\", \"text\",\"text\", \"text\", \"text\", \"text\", \n                \"numeric\", \"numeric\", \"numeric\",\n                \"text\", \"text\",\"text\", \n                \"numeric\", \"numeric\", \"numeric\",\n       \"numeric\", \"text\", \"numeric\",\"text\", \"numeric\", \n       \"numeric\", \"text\",\"numeric\", \"text\", \"numeric\", \n       \"text\", \"text\", \"text\", \"text\", \"text\", \"numeric\",\n       \"text\", \"text\", \"text\", \"text\", \"text\", \"text\",\"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\",\"text\", \"text\",\n       \"numeric\",\"numeric\")\n\n# Data extracted from the selected papers after abstract screening\n\nset_JMGS &lt;- read_excel(here::here(\"data/input/data_extraction_setJMGS_checkedSD.xlsx\"),col_types =column_types)\nset_SD &lt;- read_excel(here::here(\"data/input/data_extraction_setSD_checkedTR.xlsx\"),col_types =column_types)\nset_TR &lt;- read_excel(here::here(\"data/input/data_extraction_setTR_checkedJS_checkedSD.xlsx\"),col_types =column_types)\n\n# Data extracted from repeated search on 12.Aug.2024\n\nset2_JMGS &lt;- read_excel(here::here(\"data/input/data_extraction_repeat_search_JMGS.xlsx\"),col_types =column_types)\nset2_SD &lt;- read_excel(here::here(\"data/input/data_extraction_repeat_search_SD.xlsx\"),col_types =column_types)\nset2_TR &lt;- read_excel(here::here(\"data/input/data_extraction_repeat_search_TR.xlsx\"),col_types =column_types)\n\n\n# Unpublished dataset\nset_unpublished1 &lt;- read_excel(here::here(\"data/input/data_extraction_MO_checkedSD.xlsx\"),col_types =column_types)\nset_unpublished2 &lt;-read_excel(here::here(\"data/input/data_extraction_UnpublishedThesis.xlsx\"),col_types =column_types)\n\n# Merge all datasets\nmerged_data_extraction&lt;-full_join(set_JMGS,set_SD)%&gt;%full_join(set_TR)%&gt;%full_join(set2_JMGS)%&gt;%full_join(set2_SD)%&gt;%full_join(set2_TR)%&gt;%full_join(set_unpublished1)%&gt;%full_join(set_unpublished2)\n\n\nExcluded articles\nNumber of studies that were excluded from out data extraction process: 16 .\n\n\n\nReasons for exclusion\n\n\n\n\n\n\n\nNumber of studies excluded\n\n\n\n\nGreen nest material is not the independent variable\n6\n\n\nNo fitness proxy measured\n7\n\n\nNot empirical\n1\n\n\nNot experimental\n2\n\n\n\n\n\nIncluded articles\nNumber of studies that are included in our meta-analysis so far: 29",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "data_cleaning.html#proxies-of-fitness",
    "href": "data_cleaning.html#proxies-of-fitness",
    "title": "2  Data Cleaning",
    "section": "2.2 Proxies of fitness",
    "text": "2.2 Proxies of fitness\nWe extracted the names of the variables that the authors measured as it is. We will now clean them a bit, making sure they are all named correctly. We are cleaning some of the names of the fitness proxy and storing them in the new variable called fitness_proxy_cleaned\n\n2.2.1 Un-categorized variables\n\n2.2.1.1 1. Number of nestlings (different age)\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"number of nestling\", \n                                    ignore_case = TRUE)) ~ \"number_of_nestling\",\n    str_detect(fitness_proxy, regex(\"Number of hatchlings\", \n                                    ignore_case = TRUE)) ~ \"number_of_nestling\",\n    str_detect(fitness_proxy, regex(\"broodsize\", \n                                    ignore_case = TRUE)) ~ \"number_of_nestling\",  \n    str_detect(fitness_proxy, regex(\"brood size\", \n                                    ignore_case = TRUE)) ~ \"number_of_nestling\",\n    str_detect(fitness_proxy, regex(\"number of eggs hatched\", \n                                    ignore_case = TRUE)) ~ \"number_of_nestling\",\n    str_detect(fitness_proxy, regex(\"maxchicks*\", \n                                    ignore_case = TRUE)) ~ \"number_of_nestling\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.2 2. Number of fledglings\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"number of fled\", \n                                    ignore_case = TRUE)) ~ \"number_of_fledgling\",\n    str_detect(fitness_proxy, regex(\"number fled\", \n                                    ignore_case = TRUE)) ~ \"number_of_fledgling\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.3 3. Chick mass, nestling mass and fledgling mass\n\n\nCode\n# Checked paper GNM_069 and GNM_349 and the word body mass is used to describe nestlings of 14 days and 17 days respectlively\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"chick mass*\", ignore_case = TRUE)) ~ \"chick_mass\",\n    str_detect(fitness_proxy, regex(\"chick body mass\", ignore_case = TRUE)) ~ \"chick_mass\",\n     str_detect(fitness_proxy, regex(\"chickmass\", ignore_case = TRUE)) ~ \"chick_mass\",\n    str_detect(fitness_proxy, regex(\"fledgling mass\", ignore_case = TRUE)) ~ \"fledgeling_mass\",\n    str_detect(fitness_proxy, regex(\"fledgling body mass\", ignore_case = TRUE)) ~ \"fledgeling_mass\",str_detect(fitness_proxy, regex(\"nestling mass\", ignore_case = TRUE)) ~ \"nestling_mass\",\n    str_detect(fitness_proxy, regex(\"nestlings mass\", ignore_case = TRUE)) ~ \"nestling_mass\",\n    str_detect(fitness_proxy, regex(\"nestling weight\", ignore_case = TRUE)) ~ \"nestling_mass\",    str_detect(fitness_proxy, regex(\"body mass\", ignore_case = TRUE)) ~ \"nestling_mass\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.4 4. Nestling survival rate\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"nestling survival rate\", \n                                    ignore_case = TRUE)) ~ \"survival_rate_nestling\", \n    \n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.5 5. Recruitment probability\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"probability of local recruitment\" , \n                                   ignore_case = TRUE)) ~ \"local_recruitment_probability\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.6 6. Hatching success\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"hatching success*\" , \n                                   ignore_case = TRUE)) ~ \"hatching_success\",\n   str_detect(fitness_proxy, regex(\"hatch success*\" , \n                                   ignore_case = TRUE)) ~ \"hatching_success\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.7 7. Fledgling success\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"fledging success*\" , \n                                   ignore_case = TRUE)) ~ \"fledgling_success\",\n   str_detect(fitness_proxy, regex(\"fledge success*\" , \n                                   ignore_case = TRUE)) ~ \"fledgling_success\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.8 7. Reproductive success\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"reproductive success\" , \n                                   ignore_case = TRUE)) ~ \"reproductive_success\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.9 8. Nest mortality\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"Nest mortality\" , \n                                   ignore_case = TRUE)) ~ \"nest_mortality\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.10 9. Male and female dispersal distance\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"dispersal distance (meters) males*\", ignore_case = TRUE))\n    ~ \"dispersal_distance_males\",    \n    str_detect(fitness_proxy, regex(\"dispersal distance (meters) females*\", ignore_case = TRUE)) \n    ~ \"dispersal_distance_females\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.1.11 10. Mouth colouration\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"brightness\" , \n                                   ignore_case = TRUE)) ~ \n     \"mouth_colouration\",\n   str_detect(fitness_proxy, regex(\"hue\" , \n                                   ignore_case = TRUE)) ~ \n     \"mouth_colouration\",\n      str_detect(fitness_proxy, regex(\"saturation\" , \n                                   ignore_case = TRUE)) ~ \n     \"mouth_colouration\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n\n2.2.2 For variables that fit courtship hypothesis\n\n2.2.2.1 1. Male and female proportion of visit\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"male proportions of visit\" , \n                                   ignore_case = TRUE)) ~ \n     \"male_visit\",\n   str_detect(fitness_proxy, regex(\"female proportions of visit\" , \n                                   ignore_case = TRUE)) ~ \n     \"female_visit\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.2 2. Male and female provisioning\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n     str_detect(fitness_proxy, regex(\"female provisioning rate\" , \n                                   ignore_case = TRUE)) ~ \n     \"female_provisioning_rate\",\n   str_detect(fitness_proxy, regex(\"male provisioning rate\" , \n                                   ignore_case = TRUE)) ~ \n     \"male_provisioning_rate\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.3 3. Male food provisioning\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"male food provisioning*\" , \n                                   ignore_case = TRUE)) ~ \n     \"male_provisioning\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.4 4. Male incubation attendance\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"male incubation attendance*\" , \n                                   ignore_case = TRUE)) ~ \n     \"male_incubation_attendance\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.5 5. Male Risk Taking\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"male risk*\" , \n                                   ignore_case = TRUE)) ~ \n     \"male_risk_taking\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.6 6. Female Testosterone\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"females' testosterone level*\" , \n                                   ignore_case = TRUE)) ~ \n     \"females_testosterone\",\n   str_detect(fitness_proxy, regex(\"testosterone level*\" , \n                                   ignore_case = TRUE)) ~ \n     \"females_testosterone\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.7 7. Courtship Time\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"courtship time*\" , \n                                   ignore_case = TRUE)) ~ \n     \"courtship_time\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.8 8. Clutch size\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"clutch size\", \n                                    ignore_case = TRUE)) ~ \"clutch_size\",\n    str_detect(fitness_proxy, regex(\"clutch-size\", \n                                    ignore_case = TRUE)) ~ \"clutch_size\",\n     str_detect(fitness_proxy, regex(\"eggslaid\", \n                                     ignore_case = TRUE)) ~ \"clutch_size\",\n    str_detect(fitness_proxy, regex(\"Number of eggs\", \n                                     ignore_case = TRUE)) ~ \"clutch_size\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.9 10. Egg Size\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"egg size*\" , \n                                   ignore_case = TRUE)) ~ \n     \"egg_size\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.10 11. Laying Date\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"laying date\", ignore_case = TRUE))\n    ~ \"laying_date\",    \n    str_detect(fitness_proxy, regex(\"clutch initiation date\", ignore_case = TRUE)) \n    ~ \"laying_date\",\n      str_detect(fitness_proxy, regex(\"Onset of Laying\", ignore_case = TRUE)) \n    ~ \"laying_date\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.11 12. Hatching Date\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"hatching date\", ignore_case = TRUE))\n    ~ \"hatching_date\",    \n    TRUE ~ as.character(fitness_proxy_cleaned)  # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.12 13. Yolk Hormones\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"Yolk Log T (testosterone)*\" , \n                                   ignore_case = TRUE)) ~ \n     \"yolk_hormones\",\n    str_detect(fitness_proxy, regex(\"Yolk Log A4(androstenedione)*\" , \n                                   ignore_case = TRUE)) ~ \n     \"yolk_hormones\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.13 14. Male and female body size\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"female body size\", ignore_case = TRUE)) \n    ~ \"female_bodysize\",\n    str_detect(fitness_proxy, regex(\"male body size\", ignore_case = TRUE))\n    ~ \"male_bodysize\",    \n    TRUE ~ as.character(fitness_proxy_cleaned)  # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.14 15. Male and female mass\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n      str_detect(fitness_proxy, regex(\"female mass\", ignore_case = TRUE)) \n    ~ \"female_mass\",\n    str_detect(fitness_proxy, regex(\"male mass\", ignore_case = TRUE))\n    ~ \"male_mass\",    \n    TRUE ~ as.character(fitness_proxy_cleaned)  # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.15 16. Male and female wing length\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n      str_detect(fitness_proxy, regex(\"female wing length\", ignore_case = TRUE)) \n    ~ \"female_winglength\",\n    str_detect(fitness_proxy, regex(\"male wing length\", ignore_case = TRUE))\n    ~ \"male_winglength\",    \n    TRUE ~ as.character(fitness_proxy_cleaned)  # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.16 17. Male and female tarsus length\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n  str_detect(fitness_proxy, regex(\"female tarsus length\", ignore_case = TRUE)) \n    ~ \"female_tarsus_length\",\n    str_detect(fitness_proxy, regex(\"male tarsus length\", ignore_case = TRUE))\n    ~ \"male_tarsus_length\",    \n    TRUE ~ as.character(fitness_proxy_cleaned)  # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.2.17 18. Sex Ratio\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"Sex ratio offspring*\", ignore_case = TRUE))\n    ~ \"sex_ratio\",    \n   str_detect(fitness_proxy, regex(\"proportion of males per breeding attempt\", \n                                   ignore_case = TRUE))\n    ~ \"sex_ratio\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  # Keeps existing values for all other cases\n  ))\n\n\n\n\n\n2.2.3 For variables that fit nest protection hypothesis:\n\n2.2.3.1 1. Number of mites\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"\\\\bmite(s)?\\\\b\", ignore_case = TRUE)) ~ \"mites\",\n    str_detect(fitness_proxy, regex(\"mite load*\", ignore_case = TRUE)) \n    ~ \"mites\",\n    str_detect(fitness_proxy, regex(\"mites_score\", ignore_case = TRUE)) \n    ~ \"mites\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.2 3. Number of fleas\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"number of fleas*\", ignore_case = TRUE)) \n    ~ \"fleas_number\",\n    str_detect(fitness_proxy, regex(\"fleas*\", ignore_case = TRUE)) \n    ~ \"fleas_number\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.3 4. Ticks Load\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"tick load in the nest*\", ignore_case = TRUE)) \n    ~ \"tick_load\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.4 5. Number of blowfly\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\n  mutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"\\\\bblowfl(ies|y)\\\\b\", ignore_case = TRUE)) ~ \"blowflies_number\",\n    str_detect(fitness_proxy, regex(\"Protocalliphora*\", ignore_case = TRUE)) ~ \"blowflies_number\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.5 6. Number of blowflies parasitoids\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"blowfly parasitoid*\", ignore_case = TRUE)) \n    ~ \"blowfly_parasitoids_number\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.6 7. Number of Midges\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"number of biting midges*\", ignore_case = TRUE)) \n    ~ \"midges_number\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.7 8. Number of Blackflies\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"number of blackfl*\", ignore_case = TRUE)) \n    ~ \"blackflies_number\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.8 9. Carnus flies load\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"Log Carnus flies*\", ignore_case = TRUE)) \n    ~ \"carnusflies_load\",\n    str_detect(fitness_proxy, regex(\"carnus*\", ignore_case = TRUE)) \n    ~ \"carnusflies_load\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.9 10. Bacterial Load\nThere are several different kinds of bacterial that authors have measures like enterococcus/enterobacteria or mesophilic bacterial. In some cases authors do not give description of what bacteria they measure the load for.\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"total bacterial load*\", ignore_case = TRUE)) \n    ~ \"bacterial_load\",\n    str_detect(fitness_proxy, regex(\"bacteria load*\", ignore_case = TRUE)) \n    ~ \"bacterial_load\",\n     str_detect(fitness_proxy, regex(\"load of enterobacteria*\", ignore_case = TRUE)) \n    ~ \"bacterial_load\",\n     str_detect(fitness_proxy, regex(\"log mesophilic bacteria*\", ignore_case = TRUE)) \n    ~ \"bacterial_load\",\n     str_detect(fitness_proxy, regex(\"log enterococcus*\", ignore_case = TRUE)) \n    ~ \"bacterial_load\",\n      str_detect(fitness_proxy, regex(\"mesophilic bacterial density (log)*\", \n                                      ignore_case = TRUE)) \n    ~ \"bacterial_load\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.10 11. Bacterial Richness\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"bacterial_richness*\", ignore_case = TRUE)) \n    ~ \"bacterial_richness\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.11 12. Bacterial Increase\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"bacterial increase*\", ignore_case = TRUE)) \n    ~ \"bacterial_increase\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.3.12 13. Scab Score\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"\\\\bscab(s)?\\\\b\", ignore_case = TRUE)) ~ \"scab_score\",   \n    str_detect(fitness_proxy, regex(\"scab_score\", ignore_case = TRUE)) ~ \"scab_score\",   \n    TRUE ~ as.character(fitness_proxy_cleaned)  # Keeps existing values for all other cases\n  ))\n\n\n\n\n\n2.2.4 For Variables that fit Drug Hypothesis + Nest Protection (Parental care)\n\n2.2.4.1 1. Haemoglobin Measure\nHematocrit level is combined here with haemoglobin concentration as “hemoglobin_measure”. Hematocrit is measured as a percentage as compared to Haemoglobin which is a w/V concentration.\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"hemoglobin concentration*\", ignore_case = TRUE)) \n    ~ \"hemoglobin_measure\",\n    str_detect(fitness_proxy, regex(\"blood haemoglobin*\", ignore_case = TRUE)) \n    ~ \"hemoglobin_measure\",\n     str_detect(fitness_proxy, regex(\"heamatocrit percent*\", ignore_case = TRUE)) \n    ~ \"hemoglobin_measure\",\n    str_detect(fitness_proxy, regex(\"hematocrit level*\", ignore_case = TRUE)) \n    ~ \"hemoglobin_measure\",\n    str_detect(fitness_proxy, regex(\"haematocrit\", ignore_case = TRUE)) \n    ~ \"hemoglobin_measure\",\n    TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.2 2. Glucose Measure\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n    str_detect(fitness_proxy, regex(\"glucose concentration*\", ignore_case = TRUE)) \n    ~ \"glucose_measure\",\n     TRUE ~ as.character(fitness_proxy_cleaned)  \n    # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.3 3. Nestling Tarsus Length\n\n\nCode\n#checked paper GNM_069 word tarsus length is used to describe nestlings of 14 days\n\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"nestling tarsus length\" , ignore_case = TRUE)) ~ \"nestling_tarsus_length\",\n      str_detect(fitness_proxy,\"tarsal length\") ~ \"nestling_tarsus_length\",\n   str_detect(fitness_proxy,\"Tarsus Length*\") ~ \"nestling_tarsus_length\",\n   \n    TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.4 4. Nestling Wing Length\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"nestling wing*\" , ignore_case = TRUE)) \n   ~ \"nestling_wing_length\",\n   str_detect(fitness_proxy, regex(\"length of primary flight feather length of nestlings at day 12\" , \n                                   ignore_case = TRUE)) \n   ~ \"nestling_wing_length\",\n   TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.5 5. Nestling Immunity\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"nestling PHA*\" , ignore_case = TRUE)) \n   # PHA is phytohaemagglutinin and single-wing phytohaemagglutinin is used as a measure of immunity in avian biology: \n   # Smits, J.E., Bortolotti, G.R. and Tella, J.L. (1999), Simplifying the phytohaemagglutinin skin-testing technique in studies of avian immunocompetence. Functional Ecology, 13: 567-572. https://doi.org/10.1046/j.1365-2435.1999.00338.x\n   ~ \"nestling_immunity\",\n   str_detect(fitness_proxy, regex(\"Phytohaemagglutinin*\" , ignore_case = TRUE)) \n   ~ \"nestling_immunity\",\n   TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.6 6. Nestling Size\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"nestling size*\" , ignore_case = TRUE)) \n   ~ \"nestling_size\",\n   TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.7 7. Nestling Leukocytes\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"nestling leukocyte*\" , ignore_case = TRUE)) \n   ~ \"nestling_leukocytes\",\n   str_detect(fitness_proxy, regex(\"WBC measure of nestlings\" , ignore_case = TRUE)) \n   ~ \"nestling_leukocytes\",\n   TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.8 8. Chick Feather Development\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"chick feather development*\" , ignore_case = TRUE)) \n   ~ \"chick_feather_development\",\n   TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.9 9. Development Score\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"meandevoscore*\" , ignore_case = TRUE)) \n   ~ \"clutch_development_score\",\n   TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.10 10. Female body condition (Tarsus/wing)\nHere the authors have studied the effect of parasite on he adult female (yearlings) measured at two time point to understand how the parasite load effects the adults in the nest (GNM_101)\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"female body condition*\" , ignore_case = TRUE)) \n   ~ \"female_body_condition\",\n   TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.11 11. Telomere measure\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"Rank telomere length*\" , \n                                   ignore_case = TRUE)) \n   ~ \"telomere_measure\",\n   str_detect(fitness_proxy, regex(\"Rank difference in Telomere length*\" , \n                                   ignore_case = TRUE))\n   ~ \"telomere_measure\",\n   TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n2.2.4.12 12. Fat Score\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\nmutate(fitness_proxy_cleaned = case_when(\n   str_detect(fitness_proxy, regex(\"fat score*\" , ignore_case = TRUE)) \n   ~ \"fat_score\",\n   TRUE ~ as.character(fitness_proxy_cleaned)  \n   # Keeps existing values for all other cases\n  ))\n\n\n\n\n\n\n\n\nTo Check the dataset:\n\n\n\nSome questions to ask AST\n\n2.3 Ask AST\n\nNest mortality and reproductive success, can we club them under similar fitness proxy?\nFledgling success vs survival to fledgling vs. survival rate nestling, how do these differ?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "data_cleaning.html#ask-ast",
    "href": "data_cleaning.html#ask-ast",
    "title": "2  Data Cleaning",
    "section": "2.3 Ask AST",
    "text": "2.3 Ask AST\n\nNest mortality and reproductive success, can we club them under similar fitness proxy?\nFledgling success vs survival to fledgling vs. survival rate nestling, how do these differ?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "data_cleaning.html#we-excluded-some-proxies-from-our-dataset",
    "href": "data_cleaning.html#we-excluded-some-proxies-from-our-dataset",
    "title": "2  Data Cleaning",
    "section": "2.4 We excluded some proxies from our dataset",
    "text": "2.4 We excluded some proxies from our dataset\n\n\n\nExcluded proxies\n\n\n\n\n\n\n\nPaper ID\nFitness Trait\nReason for exclusion\n\n\n\n\nGNM_152\nmale food provisioning\nThis is only tested non-experimentally with correlational data.\n\n\nGNM_152\nmale incubation attendance\nThis is only tested non-experimentally with correlational data.\n\n\nGNM_152\nmale body size\nThis is only tested non-experimentally with correlational data.\n\n\nGNM_152\nmale tarsus length\nThis is only tested non-experimentally with correlational data.\n\n\nGNM_152\nmale wing length\nThis is only tested non-experimentally with correlational data.\n\n\nGNM_152\nfemale body size\nThis is only tested non-experimentally with correlational data.\n\n\nGNM_152\nfemale tarsus length\nThis is only tested non-experimentally with correlational data.\n\n\nGNM_152\nfemale wing length\nThis is only tested non-experimentally with correlational data.\n\n\nGNM_237\nlog mesophilic bacteria\nThere is an additional treatment of contaminating the eggs with bacteria.. This is not comparable across studies and an exceptional case of artificial contamination\n\n\nGNM_237\nlog mesophilic bacteria\nThere is an additional treatment of contaminating the eggs with bacteria.. This is not comparable across studies and an exceptional case of artificial contamination\n\n\nGNM_237\nlog mesophilic bacteria\nThere is an additional treatment of contaminating the eggs with bacteria.. This is not comparable across studies and an exceptional case of artificial contamination\n\n\nGNM_018\nfemale provisioning rate (day 6)\nWe will exclude this variable from all our analysis altogether. Since females add the GNM as noted by the authors, it is the male that would/should adjust their investment. One can argue female investment will be an indirect reflection of the male’s investment. However, this is very indirect and the direction of this proxy in relation to the GNM addition can be argued both ways. That is, if females use GNM as an honest signal to increase male investment, their own investment would not be directly related to fitness or they would increase investment to compensate for the lack of male investment. Or it would be negatively related to fitness because they invested in bringing in the GNM as well as in higher provisioning. Therefore, we will exclude it.\n\n\nGNM_018\nfemale provisioning rate (day 11)\nWe will exclude this variable from all our analysis altogether. Since females add the GNM as noted by the authors, it is the male that would/should adjust their investment. One can argue female investment will be an indirect reflection of the male’s investment. However, this is very indirect and the direction of this proxy in relation to the GNM addition can be argued both ways. That is, if females use GNM as an honest signal to increase male investment, their own investment would not be directly related to fitness or they would increase investment to compensate for the lack of male investment. Or it would be negatively related to fitness because they invested in bringing in the GNM as well as in higher provisioning. Therefore, we will exclude it.\n\n\nGNM_018\nreproductive success\nThese values are already provided in GNM_101, therefore, duplicated. How I make the decision they are the same results is because the values reported in GNM_101 and the ones I calculated from the dataset provided by the authors match 100% for these variables and the study year and population is the same.\n\n\nGNM_018\nhatch success\nThese values are already provided in GNM_101, therefore, duplicated. How I make the decision they are the same results is because the values reported in GNM_101 and the ones I calculated from the dataset provided by the authors match 100% for these variables and the study year and population is the same.\n\n\nGNM_018\nlaying date\nThese values are already provided in GNM_101, therefore, duplicated. How I make the decision they are the same results is because the values reported in GNM_101 and the ones I calculated from the dataset provided by the authors match 100% for these variables and the study year and population is the same.\n\n\nGNM_018\nclutch size\nThese values are already provided in GNM_101, therefore, duplicated. How I make the decision they are the same results is because the values reported in GNM_101 and the ones I calculated from the dataset provided by the authors match 100% for these variables and the study year and population is the same.\n\n\nGNM_018\nhatching date\nThese values are already provided in GNM_101, therefore, duplicated. How I make the decision they are the same results is because the values reported in GNM_101 and the ones I calculated from the dataset provided by the authors match 100% for these variables and the study year and population is the same.\n\n\nGNM_355\nchick mass (May, Day6)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (May, Day6)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (May, Day6)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (May, Day12)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (May, Day12)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (May, Day12)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (May, Day18)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (May, Day18)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (May, Day18)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (June, Day6)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (June, Day6)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (June, Day6)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (June, Day12)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (June, Day12)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (June, Day12)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (June, Day18)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (June, Day18)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_355\nchick mass (June, Day18)\nWe have combined the means, standard deviations and sample sizes for different months together for this paper. We realised that the sample size was as low as 1 in some cases, with effective sample size being 0.5 which does not allow us to estimate the effect size (SMDH specifically). Instead of removing this data, we decided to combine the months together, in this article for all the fitness traits.\n\n\nGNM_1_Unpublished\nNumber of green twigs added by parents\nNA\n\n\nGNM_1_Unpublished\nNumber of green twigs added by parents\nNA\n\n\nGNM_1_Unpublished\nNumber of green twigs added by parents\nNA\n\n\nGNM_1_Unpublished\nNumber of green twigs added by parents\nNA\n\n\nGNM_1_Unpublished\nNumber of green twigs added by parents\nNA\n\n\nGNM_1_Unpublished\nNumber of green twigs added by parents\nNA\n\n\n\n\n\n\n2.4.1 Adding Observation ID column\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\n  mutate(Observation_ID=row_number(), .before = experiment_ID)\n\n\n\n\n2.4.2 Adding Hypothesis column\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\n  mutate(Hypothesis= case_when(\n      CH == 1 & PCH == 0 ~ \"CH\",   \n      CH == 0 & PCH == 1 ~ \"PCH\",  \n      CH == 1 & PCH == 1 ~ \"both\") \n    ,.after = PCH)\n\n#checked, has no NAs\n\n\n\n2.4.2.1 Cleaning Type of trait studied\n(levels: physiology, morphology, reproduction, behaviour, parasite and pathogenic load, phenology)\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\n  mutate(trait_type = case_when(\n    str_detect(trait_type, regex(\"physiology\", ignore_case = TRUE)) ~ \"Physiology\",\n    str_detect(trait_type, regex(\"reproduction\", ignore_case = TRUE)) ~ \"Reproduction\",\n    str_detect(trait_type, regex(\"morphology\", ignore_case = TRUE)) ~ \"Morphology\",\n    str_detect(trait_type, regex(\"parasite.*pathogenic|parasitic.*pathogenic\", ignore_case = TRUE)) ~ \"Parasitic_and_pathogenic\",\n    str_detect(trait_type, regex(\"behaviour\", ignore_case = TRUE)) ~ \"Behaviour\",\n    str_detect(trait_type, regex(\"phenology\", ignore_case = TRUE)) ~ \"Phenology\",\n    TRUE ~ as.character(trait_type)\n  ))\n\n\n\n\n\n2.4.3 Adding Type of parasites\n(levels: arthropods, micro-organisms) \n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\n  mutate(parasite_type= case_when(\n    str_detect(parasite_type, regex(\"arthropod\", ignore_case = TRUE)) ~ \"Arthropod\",\n    str_detect(parasite_type, regex(\"micro[- ]?organism|microoragnism\", ignore_case = TRUE)) ~ \"Micro-organism\",\n    is.na(parasite_type) ~ NA_character_,  # Keep NA as it is\n    TRUE ~ as.character(parasite_type)    # Retain other values (optional, if needed)\n  ))\n\n\n\n\n2.4.4 Time of addition of green nest material\n(levels: before egg hatching, after egg hatching, continuously throughout the nesting phase).\n\n\n2.4.5 Type of experimental design\n(levels: 1 = non-aromatic vs. aromatic, 2 = no added material vs. aromatic, 3 = no added material vs. non-aromatic).\n\n\n2.4.6 Bird species\n(levels: Cyanistes caeruleus, Sturnus unicolor, Tachycineta bicolor, Sturnus vulgaris; note that these levels reflect the list of species studied in our current database, which may increase after updating our search and/or receiving unpublished data from authors)\n\n\nCode\ndataset_after_cleaning &lt;- dataset_after_cleaning %&gt;%\n  mutate(bird_species= case_when(\n    str_detect(bird_species, regex(\"Cyanistes caeruleus, Parus major\", ignore_case = TRUE)) ~ \"Cyanistes caeruleus\",\n    str_detect(bird_species, regex(\"Cyanistes caeruleus|Cyanistes_caeruleus\", ignore_case = TRUE)) ~ \"Cyanistes caeruleus\",\n    str_detect(bird_species, regex(\"Sturnus unicolor|Sturnus_unicolor\", ignore_case = TRUE)) ~ \"Sturnus unicolor\",\n        str_detect(bird_species, regex(\"Sturnus vulgaris|Sturnus_vulgaris\", ignore_case = TRUE)) ~ \"Sturnus vulgaris\",\n    TRUE ~ as.character(bird_species)\n  ))\n\n\nWhichever between Cyanistes caeruleus and Parus major is higher.. assign that..\n\n\nCode\nwrite.csv(dataset_after_cleaning,file=here::here(\"data/input/dataset_after_cleaning.csv\"),row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "data_preparation.html",
    "href": "data_preparation.html",
    "title": "3  Data Preparation and Exploration",
    "section": "",
    "text": "3.1 Setting up workspace",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Preparation and Exploration</span>"
    ]
  },
  {
    "objectID": "data_preparation.html#setting-up-workspace",
    "href": "data_preparation.html#setting-up-workspace",
    "title": "3  Data Preparation and Exploration",
    "section": "",
    "text": "3.1.0.1 Loading functions\nSome functions we will need in this manuscript.. sourced mainly from Nakagawa 2022 : Online tutorial https://alistairmcnairsenior.github.io/Miss_SD_Sim/\n\n\nCode\n# Function to calculate Geary's \"number\"\n  geary &lt;- function(mean, sd, n){\n    (1 / (sd / mean)) * ((4*n^(3/2)) / (1 + 4*n))\n  }\n\n  \n\n# Shinichi Nakagawa, Daniel W. A. Noble, Malgorzata Lagisz, Rebecca Spake, Wolfgang Viechtbauer and Alistair M. Senior. 2022. A robust and readily implementable method for the meta-analysis of response ratios with and without missing standard deviations. Ecology Letters, DOI: 10.1111/ele.14144\n\n\n  # Functions provided in the workalong\ncv_avg &lt;- function(x, sd, n, group, data, label = NULL, sub_b = TRUE, cv2=FALSE){\n\n  # Check if the name is specified or not. If not, then assign it the name of the mean, x, variable input in the function. https://stackoverflow.com/questions/60644445/converting-tidyeval-arguments-to-string\n  if(is.null(label)){\n    label &lt;- purrr::map_chr(enquos(x), rlang::as_label)\n  }\n\n  # Calculate between study CV. Take weighted mean CV within study, and then take a weighted mean across studies of the within study CV. Weighted based on sample size and pooled sample size.\n  b_grp_cv_data &lt;- data                                             %&gt;%\n    dplyr::group_by({{group}})                            %&gt;%\n    dplyr::mutate(   w_CV2 = weighted_CV({{sd}}, {{x}}, {{n}}, cv2=cv2),\n                     n_mean = mean({{n}}, na.rm = TRUE))   %&gt;%\n    dplyr::ungroup(.)                                     %&gt;%\n    dplyr::mutate(b_CV2 = weighted.mean(w_CV2, n_mean, na.rm = TRUE), .keep = \"used\")\n\n  # Make sure that label of the calculated columns is distinct from any other columns\n  names(b_grp_cv_data) &lt;- paste0(names(b_grp_cv_data), \"_\", label)\n\n  # Append these calculated columns back to the original data and return the full dataset.\n  if(sub_b){\n    b_grp_cv_data &lt;- b_grp_cv_data %&gt;% dplyr::select(grep(\"b_\", names(b_grp_cv_data)))\n    dat_new &lt;- cbind(data, b_grp_cv_data)\n  } else {\n    dat_new &lt;- cbind(data, b_grp_cv_data)\n  }\n\n  return(data.frame(dat_new))\n}\n\n# You also need the helper function\n\nweighted_CV &lt;- function(sd, x, n, cv2=FALSE){\n  if(cv2){\n    weighted.mean(na_if((sd / x)^2, Inf), n, na.rm = TRUE)\n  }else{\n    weighted.mean(na_if((sd / x), Inf), n, na.rm = TRUE)^2\n  }\n}\n\n\n#' @title lnrr_laj\n#' @description Calculates log response ratio based on Taylor expansion from Jajeunesse 2011\n#' @param m1 Mean of treatment group 1\n#' @param m2 Mean of treatment group 2\n#' @param cv1_2 Coefficient of variation squared (CV^2) for treatment group 1\n#' @param cv2_2 Coefficient of variation squared (CV^2) for treatment group 2\n#' @param n1 Sample size for treatment group 1\n#' @param n2 Sample size for treatment group 2\n#' @param taylor A logical indicating whether to calculate point estimate with Taylor expansion.\n#'\nlnrr_laj &lt;- function(m1, m2, cv1_2, cv2_2, n1, n2, taylor=TRUE){\n  if(taylor){\n    log(m1 / m2) + 0.5*((cv1_2 / n1) - (cv2_2 / n2))\n  } else {\n    log(m1 / m2)\n  }\n}\n\n#' @title v_lnrr_laj\n#' @description Calculates the sampling variance for log response ratio based on second order Taylor expansion proposed by Lajeunesse 2011\n#' @param cv1_2 Coefficient of variation squared (CV^2) for treatment group 1\n#' @param cv2_2 Coefficient of variation squared (CV^2) for treatment group 2\n#' @param n1 Sample size for treatment group 1\n#' @param n2 Sample size for treatment group 2\n#' @param taylor A logical indicating whether to calculate point estimate with Taylor expansion.\nv_lnrr_laj &lt;- function(cv1_2, cv2_2, n1, n2,  taylor=TRUE){\n  if(taylor){\n  ((cv1_2) / n1) + ((cv2_2) / n2) +\n    ((cv1_2)^2 / (2*n1^2)) + ((cv2_2)^2 / (2*n2^2))\n  } else {\n    ((cv1_2) / n1) + ((cv2_2) / n2)\n  }\n}\n\n\n\n\n3.1.1 Excluding proxies that are to be checked\n\n\n\nCode\n# selecting dataset which are not flagged or to be checked\ndataset_analysis&lt;-dataset_after_cleaning%&gt;%\n   filter(proxy_decision != \"check\")\n\n#check what is excluded (as of now 19 rows are excluded)\nexcluded_rows&lt;- anti_join(dataset_after_cleaning, dataset_analysis)\n\n\n\n\n3.1.2 Effective Sample Size Calculation\nFor comparisons involving the shared control or treatment groups across multiple studies, adjusting the sample sizes by dividing them by the number of times each group is included in comparisons. This adjustment helps to prevent any inflation of the effect sizes due to repeated use of the same groups.\n\n\nCode\ndataset_analysis&lt;-dataset_analysis%&gt;%\n  mutate(effective_n_experiment=(n_experiment/shared_experiment),.after=n_experiment)%&gt;%\n  mutate(effective_n_control=(n_control/shared_control),.after=n_control)\n\n\nChecking the range of effective sample size in our dataset\n\n\nCode\ndataset_analysis%&gt;%\n  summarise(control_min=min(effective_n_control,na.rm=T),\n            control_max=max(effective_n_control,na.rm=T),\n            na_control = sum(is.na(effective_n_control)),\n            experiment_min=min(effective_n_experiment,na.rm=T),\n            experiment_max=max(effective_n_experiment,na.rm=T),\n             na_experiment = sum(is.na(effective_n_experiment)))\n\n\n\n  \n\n\n\nWe have some NA and some values of effective sample size 1 and below.. lets see where this is\n\n\nCode\ndataset_analysis%&gt;%\n  filter(effective_n_control&lt;2 | effective_n_experiment&lt;2)\n\n\n\n  \n\n\n\nMany of these data points come from GNM_355. There are datapoints with sample size of 1 for some groups. We have extracted data by days and months.. I will combine these for this paper because of such low sample size. (We cannot estimate SMHD with 0.5 as an effective sample size)\n\n\n3.1.3 Converting variance to SD\nThere were no other measure of dispersion, only SE and SD, so no need to convert anything more.\n\n\nCode\n## Calculating sd from difference variance measures (only for se so far)\n\n# For experimental group\ndataset_analysis &lt;- dataset_analysis %&gt;%\n  mutate(sd_experiment = if_else(type_measure_dispersion_experiment %in% c('se', 'SE'), #condition to check\n      measure_dispersion_experiment * sqrt(as.numeric(n_experiment)), # do this if true\n      measure_dispersion_experiment), #else do this\n      .after=measure_dispersion_experiment)\n# For control group\ndataset_analysis &lt;- dataset_analysis %&gt;%\n  mutate(sd_control = if_else(type_measure_dispersion_control %in% c('se', 'SE'), #condition to check\n      measure_dispersion_control* sqrt(as.numeric(n_control)), # do this if true\n      measure_dispersion_control), #else do this\n      .after=measure_dispersion_control)\n\n\nSome checks for the value of mean and SD\n\n\nCode\n# Some rows contain NAs, check why\n# contains_NA&lt;-dataset_analysis%&gt;%\n# filter(is.na(measure_central_tendency_experiment)|is.na(measure_dispersion_experiment))\n\n# 13 rows contain NA and I checked them manually, everything looks okay. \n# - 4 rows contain only statistical test values and \n# - 9 are missing data that authors did not provide for which we will use 0 as effect size. \n\n\n\n\n3.1.4 Preparing Random Effects\nWe will include the following random effects in all our models unless stated otherwise: \n\n(1) paper_ID, which encompasses estimates extracted from the same primary study\n(2) experiment_ID\n(3) group_ID\n(4) repeated_traits_ID\n(5) observation_ID,\n\nwhich corresponds to a unit-level observation identity and models within-study variance (for more details on the selection of random effects (see Section Miscellaneous synthesis details).\n\n\nCode\ndataset_analysis&lt;-dataset_analysis%&gt;%\n  mutate(Observation_ID = as.factor(row_number()))%&gt;%\n  mutate(experiment_ID_coded = as.factor(paste(paper_ID, experiment_ID, sep=\"_\")),.after=experiment_ID)%&gt;%\n  mutate(group_ID_coded = as.factor(paste(paper_ID, group_ID, sep=\"_\")),.after=group_ID)%&gt;%\n  mutate(repeated_trait_ID_coded = as.factor(paste(paper_ID,group_ID, repeated_trait_ID, sep=\"_\")),.after=repeated_trait_ID)\n\n# random_effects_check&lt;-dataset_analysis%&gt;%select(paper_ID,experiment_ID,group_ID,repeated_trait_ID, experiment_ID_coded,group_ID_coded, repeated_trait_ID_coded)\n\n# write.csv(dataset_analysis,file=here::here(\"data/input/dataset_analysis.csv\"),row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Preparation and Exploration</span>"
    ]
  },
  {
    "objectID": "data_preparation.html#effect-size-estimation",
    "href": "data_preparation.html#effect-size-estimation",
    "title": "3  Data Preparation and Exploration",
    "section": "3.2 Effect Size Estimation",
    "text": "3.2 Effect Size Estimation\n\n3.2.1 Geary’s Test\n\n\nCode\n# Assumption of normality assumed to be approximately correct when values are &gt;= 3.\ndataset_analysis&lt;- dataset_analysis %&gt;% \n         mutate(geary_control = geary(measure_central_tendency_control,\n                                      sd_control, \n                                      n_control),\n                    geary_trt = geary(measure_central_tendency_experiment,\n                                      sd_experiment, \n                                      n_experiment),\n                   geary_test = ifelse(geary_control &gt;= 3 & geary_trt &gt;= 3, \"pass\", \"fail\"))\n\n# How many fail?\n    geary_res &lt;-dataset_analysis %&gt;% group_by(geary_test) %&gt;% summarise(n = n()) %&gt;%  data.frame()\n    \n    geary_res\n\n\n\n  \n\n\n\n88 observations fail Geary’s test\n\n\n3.2.2 No effect size provided\nWe will calculate the mean trait values by group (for now I use the mean of both experimental and control group, we can change it later if we want but since I only needed one value, this was good.\n\n\nCode\n# To calculate means by groups\ntrait_mean&lt;- dataset_analysis%&gt;%group_by(trait_type)%&gt;%\n  summarise(\n    cumulative_mean = mean (\n      c(measure_central_tendency_experiment,measure_central_tendency_control),\n      na.rm=T\n    ),\n    count = n()\n  )%&gt;%\n  arrange(desc(count))\n\n# Now I need to assign the mean values from this to the missing ES proxies\ndataset_analysis&lt;-dataset_analysis%&gt;%\n  left_join(trait_mean, by= \"trait_type\")%&gt;%\n  mutate(measure_central_tendency_experiment = if_else((\n    proxy_comment == \"use 0 as ES\" & !is.na(proxy_comment)),\n    cumulative_mean,\n    measure_central_tendency_experiment),\n    measure_central_tendency_control = if_else((\n    proxy_comment == \"use 0 as ES\" & !is.na(proxy_comment)),\n    cumulative_mean,\n    measure_central_tendency_control),)%&gt;%\n  select(-cumulative_mean)\n\n\n\n\nCode\n# Using missing-cases method approach as suggested by Nakagawa 2022 : Online tutorial - \n#  https://alistairmcnairsenior.github.io/Miss_SD_Sim/\n\n# First calculate CV on missing data set. Note missing data will be ignored\n    dataset_analysis &lt;- dataset_analysis %&gt;%\n      mutate(cv_Control = na_if(sd_control/measure_central_tendency_control, Inf),\n             cv_Experimental = na_if(sd_experiment/measure_central_tendency_experiment, Inf))\n    \n# Calculate the average between study CV, which will replace missing values.\n    dataset_analysis &lt;- cv_avg(x = measure_central_tendency_experiment, \n                                sd = sd_experiment,\n                            n = effective_n_experiment, \n                            group = paper_ID, \n                            label = \"1\",\n                             data = dataset_analysis)\n    dataset_analysis &lt;- cv_avg(measure_central_tendency_control, \n                                sd = sd_control,\n                            n = effective_n_control, \n                            group = paper_ID, \n                            label = \"2\",\n                             data = dataset_analysis)\n\n  \n# Use weighted mean CV in replacement for where CV's are missing. Otherwise, calculate CV^2 of data that is known.\n   dataset_analysis  &lt;- dataset_analysis %&gt;%\n              mutate(cv2_cont_new = if_else(is.na(cv_Control),      b_CV2_2, cv_Control^2),\n                     cv2_expt_new = if_else(is.na(cv_Experimental), b_CV2_1, cv_Experimental^2))\n\n# Now calculate new yi and vi, called lnrr_laj & v_lnrr_laj, respectively. This uses either the between individual CV^2 when missing or normal CV^2 when not missing.\n    dataset_analysis  &lt;- dataset_analysis %&gt;%\n              mutate(lnrr_laj = lnrr_laj(m1 = measure_central_tendency_experiment,\n                                         m2 = measure_central_tendency_control,\n                                         cv1_2 = cv2_expt_new, cv2_2 = cv2_cont_new,\n                                         n1= effective_n_experiment, \n                                         n2 = effective_n_control),\n                   v_lnrr_laj = v_lnrr_laj(cv1_2 = cv2_expt_new,  \n                                           n1= effective_n_experiment, \n                                           cv2_2 = cv2_cont_new, \n                                           n2 = effective_n_control))\n    \n\n# We have added 16 zeros to the dataset\n# \n# dataset_zeroES&lt;-dataset_analysis %&gt;%\n#   filter(proxy_comment == \"use 0 as ES\" & !is.na(proxy_comment))\n\n\n\n\n3.2.3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Preparation and Exploration</span>"
    ]
  }
]